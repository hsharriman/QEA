{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation Notebook\n",
    "Design Your Own Adventure Project: QEA Spring 2018  \n",
    "Hwei-Shin Harriman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(aj):\n",
    "    #Calculates the sigmoid function using logistic\n",
    "    return 1 / (1 + np.exp(-aj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigPrime(z):\n",
    "    return (z * (1 - z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcAj(weights, prevLayerOut):    \n",
    "    #Calculates the sum of the weights and outputs from previous \n",
    "    #prevLayerOut and weights must be np arrays\n",
    "    #weights should be one ROW of the weights matrix\n",
    "    #prevLayerOut should be a ROW vector\n",
    "    return np.dot(weights, prevLayerOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#given matrix of weights, number of nodes per hidden layer,\n",
    "#and an input vector of data, propagate forward for one layer\n",
    "\n",
    "def calcLayerOutputs(inputVec, weights, neuronsInLayer):\n",
    "    #define matrix of output activations for all units in current layer\n",
    "    outputs = []\n",
    "    zi = inputVec\n",
    "    for j in range(neuronsInLayer):\n",
    "        #(1 x n) dot (1 x n)\n",
    "        aj = calcAj(weights[j, :], zi)\n",
    "        outputs.append(sigmoid(aj))\n",
    "    \n",
    "    #should be j outputs\n",
    "    return np.asarray(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Same as calcLayerOutputs but doesn't pass through a sigmoid function\n",
    "def calcNetOutput(inputVec, weights, neuronsInLayer):\n",
    "    #define matrix of output activations for all units in current layer\n",
    "    outputs = []\n",
    "    zi = inputVec\n",
    "    for j in range(neuronsInLayer):\n",
    "        #(1 x n) dot (1 x n)\n",
    "        aj = calcAj(weights[j, :], zi)\n",
    "        outputs.append(aj)\n",
    "    \n",
    "    #should be j outputs\n",
    "    return np.asarray(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sumOfSquareError(netOutput, target):\n",
    "    #Takes 2 vectors of same dimensions, returns the sum-of-squares error\n",
    "    return 0.5 * np.sum(np.power(netOutput - target, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcDelta(netOutput, target):\n",
    "    #Takes 2 np arrays, all activations from forward prop and actual target\n",
    "    #returns delta value for each output neuron\n",
    "    #assumes netOutput's last entry is activations of output layer\n",
    "    sigOutk = []\n",
    "    guesses = netOutput[-1]\n",
    "    for k in range(len(guesses)):\n",
    "        sigOutk.append(sigPrime(guesses[k]))\n",
    "    return np.asarray(sigOutk) * (guesses - target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#neuronsPerLayer = array with number of neurons in each hidden/output layer\n",
    "def forwardprop(inputVec, weights, neuronsPerLayer):\n",
    "    #calculates outputs for all neurons in network\n",
    "    activations = [inputVec]\n",
    "    \n",
    "    #dynamically calculates activations for all nodes in network\n",
    "    for layer in range(len(weights)):\n",
    "        weightsInLayer = weights[layer]\n",
    "        neuronsInLayer = np.shape(weightsInLayer)[0]\n",
    "        \n",
    "        #calculates all activations for current layer\n",
    "        layerActivations = calcLayerOutputs(activations[layer], weightsInLayer[:, :], neuronsInLayer)\n",
    "        \n",
    "        #if on output layer, also calculate output without passing through sigmoid function\n",
    "        if layer == (len(weights) - 1):\n",
    "            netOut = calcNetOutput(activations[layer], weightsInLayer[:, :], neuronsInLayer)\n",
    "            #TODO: Unsure about whether this should be:\n",
    "            #layerActivations = netOut\n",
    "            \n",
    "        #adds resulting np array to list\n",
    "        activations.append(layerActivations)\n",
    "    #should be number of layers * j (neurons per layer) activations\n",
    "    return activations, netOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprop(activations, weights, deltaK):\n",
    "    #calculates deltas for hidden units\n",
    "    allDeltas = [deltaK]\n",
    "    for layer in range(len(weights) - 1, 0, -1):\n",
    "        #fetches activations from previous layer\n",
    "        zj = activations[layer - 1]\n",
    "        weightsInLayer = weights[layer]\n",
    "        \n",
    "        #empty cache list\n",
    "        deltaJs = []\n",
    "        for j in range(len(zj)):\n",
    "            dj = sigPrime(zj[j]) * np.dot(weightsInLayer[j, :], allDeltas[0])\n",
    "            deltaJs.append(dj)\n",
    "        \n",
    "        #builds list of deltas to have same indexing as weights matrix\n",
    "        allDeltas.insert(0, np.asarray(deltaJs))\n",
    "        \n",
    "    #inserts placeholder activations on input vecs for indexing in\n",
    "    #updateWeights function\n",
    "    allDeltas.insert(0, activations[0])\n",
    "    return allDeltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.21097929, 0.31070097, 0.5823619 , 0.91421451, 0.76385213,\n",
      "       0.09663155, 0.21134969, 0.0860696 , 0.29906261, 0.31482641]), array([0.60693362, 0.42291762, 0.53677095, 0.81759529, 0.88454944,\n",
      "       0.7359575 , 0.94956267, 0.83138158, 0.89805622, 0.68880227]), array([0.99070749, 0.39441403, 0.79331718, 0.69526797, 0.60117633,\n",
      "       0.05357645, 0.95099324, 0.06565698, 0.72867649, 0.98744954]), array([0.04596061, 0.18211081, 0.17127692, 0.01705417, 0.84979419,\n",
      "       0.86820292, 0.99855961, 0.36373416, 0.21627882, 0.67162766])]\n",
      "[-3.0329203  -1.50211149 -1.57660438 -4.05415903  1.73298773  1.88516201\n",
      "  6.54140033 -0.55919319 -1.28748489  0.71555596]\n"
     ]
    }
   ],
   "source": [
    "#testing functionality of forward propagation\n",
    "\n",
    "#generate random vector and weight matrix\n",
    "inputVec = np.random.rand(10)\n",
    "numLayers = 3\n",
    "weightMatrix = []\n",
    "for layer in range(numLayers):\n",
    "    weightMatrix.append(np.random.randn(10, 10))\n",
    "neuronsPerLayer = [10, 10, 10]\n",
    "activations, guessVec = forwardprop(inputVec, weightMatrix, neuronsPerLayer)\n",
    "\n",
    "#first entry of activations is the input vector\n",
    "print(activations)\n",
    "print(guessVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00201529,  0.02712476,  0.02431124, -0.01647744, -0.01917288,\n",
       "       -0.01508109,  0.00143624,  0.08417959, -0.13284254,  0.14812341])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test functionality of deltas function\n",
    "targets = np.array([0., 0., 0., 1., 1., 1. , 0., 0., 1., 0.])\n",
    "\n",
    "deltas = calcDelta(activations, targets)\n",
    "deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.21097929, 0.31070097, 0.5823619 , 0.91421451, 0.76385213,\n",
       "        0.09663155, 0.21134969, 0.0860696 , 0.29906261, 0.31482641]),\n",
       " array([-0.00365212, -0.02520321,  0.01829818, -0.00766856,  0.00302656,\n",
       "         0.00157913,  0.02849039, -0.00070579, -0.00405121, -0.00648931]),\n",
       " array([-0.02485708, -0.0540787 , -0.03010654,  0.00820516, -0.03985493,\n",
       "         0.00303697, -0.00440823,  0.0333322 ,  0.01574399,  0.03943848]),\n",
       " array([ 0.00201529,  0.02712476,  0.02431124, -0.01647744, -0.01917288,\n",
       "        -0.01508109,  0.00143624,  0.08417959, -0.13284254,  0.14812341])]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test functionality of backprop\n",
    "alldeltas = backprop(activations, weightMatrix, deltas)\n",
    "alldeltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4.45122588e-05, 6.55514684e-05, 1.22866298e-04, 1.92880323e-04,\n",
       "         1.61156976e-04, 2.03872547e-05, 4.45904068e-05, 1.81589025e-05,\n",
       "         6.30960159e-05, 6.64218516e-05],\n",
       "        [6.55514684e-05, 9.65350924e-05, 1.80940408e-04, 2.84047334e-04,\n",
       "         2.37329597e-04, 3.00235153e-05, 6.56665540e-05, 2.67419079e-05,\n",
       "         9.29190432e-05, 9.78168719e-05],\n",
       "        [1.22866298e-04, 1.80940408e-04, 3.39145388e-04, 5.32403701e-04,\n",
       "         4.44838381e-04, 5.62745316e-05, 1.23082009e-04, 5.01236557e-05,\n",
       "         1.74162672e-04, 1.83342910e-04],\n",
       "        [1.92880323e-04, 2.84047334e-04, 5.32403701e-04, 8.35788165e-04,\n",
       "         6.98324699e-04, 8.83419619e-05, 1.93218954e-04, 7.86860762e-05,\n",
       "         2.73407377e-04, 2.87818874e-04],\n",
       "        [1.61156976e-04, 2.37329597e-04, 4.44838381e-04, 6.98324699e-04,\n",
       "         5.83470077e-04, 7.38122129e-05, 1.61439912e-04, 6.57444467e-05,\n",
       "         2.28439613e-04, 2.40480827e-04],\n",
       "        [2.03872547e-05, 3.00235153e-05, 5.62745316e-05, 8.83419619e-05,\n",
       "         7.38122129e-05, 9.33765583e-06, 2.04230476e-05, 8.31703849e-06,\n",
       "         2.88988827e-05, 3.04221633e-05],\n",
       "        [4.45904068e-05, 6.56665540e-05, 1.23082009e-04, 1.93218954e-04,\n",
       "         1.61439912e-04, 2.04230476e-05, 4.46686920e-05, 1.81907832e-05,\n",
       "         6.32067905e-05, 6.65384653e-05],\n",
       "        [1.81589025e-05, 2.67419079e-05, 5.01236557e-05, 7.86860762e-05,\n",
       "         6.57444467e-05, 8.31703849e-06, 1.81907832e-05, 7.40797590e-06,\n",
       "         2.57401990e-05, 2.70969832e-05],\n",
       "        [6.30960159e-05, 9.29190432e-05, 1.74162672e-04, 2.73407377e-04,\n",
       "         2.28439613e-04, 2.88988827e-05, 6.32067905e-05, 2.57401990e-05,\n",
       "         8.94384453e-05, 9.41528092e-05],\n",
       "        [6.64218516e-05, 9.78168719e-05, 1.83342910e-04, 2.87818874e-04,\n",
       "         2.40480827e-04, 3.04221633e-05, 6.65384653e-05, 2.70969832e-05,\n",
       "         9.41528092e-05, 9.91156706e-05]]),\n",
       " array([[-2.21659306e-06, -1.52966727e-05,  1.11057826e-05,\n",
       "         -4.65430689e-06,  1.83692064e-06,  9.58428364e-07,\n",
       "          1.72917747e-05, -4.28366802e-07, -2.45881335e-06,\n",
       "         -3.93858043e-06],\n",
       "        [-1.54454497e-06, -1.06588797e-05,  7.73862412e-06,\n",
       "         -3.24316917e-06,  1.27998529e-06,  6.67842794e-07,\n",
       "          1.20490874e-05, -2.98490417e-07, -1.71332657e-06,\n",
       "         -2.74444357e-06],\n",
       "        [-1.96035073e-06, -1.35283485e-05,  9.82193318e-06,\n",
       "         -4.11626025e-06,  1.62456915e-06,  8.47632240e-07,\n",
       "          1.52928130e-05, -3.78846793e-07, -2.17456990e-06,\n",
       "         -3.48327312e-06],\n",
       "        [-2.98595433e-06, -2.06060222e-05,  1.49605085e-05,\n",
       "         -6.26977862e-06,  2.47450071e-06,  1.29109098e-06,\n",
       "          2.32936078e-05, -5.77049403e-07, -3.31224729e-06,\n",
       "         -5.30562938e-06],\n",
       "        [-3.23047873e-06, -2.22934812e-05,  1.61856477e-05,\n",
       "         -6.78322047e-06,  2.67714140e-06,  1.39682042e-06,\n",
       "          2.52011573e-05, -6.24304870e-07, -3.58349234e-06,\n",
       "         -5.74011556e-06],\n",
       "        [-2.68780350e-06, -1.85484882e-05,  1.34666853e-05,\n",
       "         -5.64373432e-06,  2.22741909e-06,  1.16217413e-06,\n",
       "          2.09677154e-05, -5.19430385e-07, -2.98151576e-06,\n",
       "         -4.77585645e-06],\n",
       "        [-3.46791474e-06, -2.39320232e-05,  1.73752718e-05,\n",
       "         -7.28177840e-06,  2.87390783e-06,  1.49948491e-06,\n",
       "          2.70534097e-05, -6.70190470e-07, -3.84687439e-06,\n",
       "         -6.16200663e-06],\n",
       "        [-3.03630348e-06, -2.09534809e-05,  1.52127726e-05,\n",
       "         -6.37549961e-06,  2.51622574e-06,  1.31286136e-06,\n",
       "          2.36863845e-05, -5.86779609e-07, -3.36809840e-06,\n",
       "         -5.39509289e-06],\n",
       "        [-3.27980710e-06, -2.26338955e-05,  1.64327973e-05,\n",
       "         -6.88679806e-06,  2.71802048e-06,  1.41814942e-06,\n",
       "          2.55859708e-05, -6.33837804e-07, -3.63821111e-06,\n",
       "         -5.82776528e-06],\n",
       "        [-2.51558701e-06, -1.73600250e-05,  1.26038301e-05,\n",
       "         -5.28212154e-06,  2.08470096e-06,  1.08770978e-06,\n",
       "          1.96242443e-05, -4.86148757e-07, -2.79048015e-06,\n",
       "         -4.46985148e-06]]),\n",
       " array([[-2.46260930e-05, -5.35761776e-05, -2.98267710e-05,\n",
       "          8.12891049e-06, -3.94845812e-05,  3.00874945e-06,\n",
       "         -4.36726175e-06,  3.30224637e-05,  1.55976887e-05,\n",
       "          3.90719947e-05],\n",
       "        [-9.80398005e-06, -2.13293995e-05, -1.18744402e-05,\n",
       "          3.23622900e-06, -1.57193448e-05,  1.19782377e-06,\n",
       "         -1.73866586e-06,  1.31466886e-05,  6.20965042e-06,\n",
       "          1.55550885e-05],\n",
       "        [-1.97195466e-05, -4.29015651e-05, -2.38840323e-05,\n",
       "          6.50929196e-06, -3.16176032e-05,  2.40928088e-06,\n",
       "         -3.49712078e-06,  2.64430095e-05,  1.24899775e-05,\n",
       "          3.12872212e-05],\n",
       "        [-1.72823299e-05, -3.75991911e-05, -2.09321104e-05,\n",
       "          5.70478285e-06, -2.77098587e-05,  2.11150834e-06,\n",
       "         -3.06489781e-06,  2.31748135e-05,  1.09462919e-05,\n",
       "          2.74203099e-05],\n",
       "        [-1.49434867e-05, -3.25108372e-05, -1.80993371e-05,\n",
       "          4.93274618e-06, -2.39598427e-05,  1.82575480e-06,\n",
       "         -2.65012067e-06,  2.00385318e-05,  9.46491406e-06,\n",
       "          2.37094790e-05],\n",
       "        [-1.33175386e-06, -2.89734475e-06, -1.61300119e-06,\n",
       "          4.39603144e-07, -2.13528566e-06,  1.62710085e-07,\n",
       "         -2.36177037e-07,  1.78582098e-06,  8.43507010e-07,\n",
       "          2.11297341e-06],\n",
       "        [-2.36389127e-05, -5.14284822e-05, -2.86311124e-05,\n",
       "          7.80304880e-06, -3.79017722e-05,  2.88813843e-06,\n",
       "         -4.19219237e-06,  3.16987001e-05,  1.49724278e-05,\n",
       "          3.75057249e-05],\n",
       "        [-1.63204060e-06, -3.55064432e-06, -1.97670420e-06,\n",
       "          5.38725814e-07, -2.61675450e-06,  1.99398308e-07,\n",
       "         -2.89430747e-07,  2.18849176e-06,  1.03370280e-06,\n",
       "          2.58941123e-06],\n",
       "        [-1.81127680e-05, -3.94058804e-05, -2.19379251e-05,\n",
       "          5.97890497e-06, -2.90413529e-05,  2.21296902e-06,\n",
       "         -3.21217007e-06,  2.42883929e-05,  1.14722752e-05,\n",
       "          2.87378909e-05],\n",
       "        [-2.45451099e-05, -5.33999920e-05, -2.97286855e-05,\n",
       "          8.10217852e-06, -3.93547358e-05,  2.99885516e-06,\n",
       "         -4.35289998e-06,  3.29138691e-05,  1.55463956e-05,\n",
       "          3.89435062e-05]])]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calcGradient(learningRate, deltas, activations, weights):\n",
    "    #for each layer, for each weight @ every node, calculate the gradient\n",
    "    gradient = []\n",
    "    for layer in range(len(weights) -1, -1, -1):\n",
    "        deltaKs = deltas[layer]\n",
    "        outJs = activations[layer]\n",
    "        weightDims = weights[layer]\n",
    "        \n",
    "        #pre-allocate array to fill with gradient values\n",
    "        weightsInLayer = np.array([[0.] * weightDims.shape[0]] * weightDims.shape[1])\n",
    "\n",
    "        for k in range(len(deltaKs)):\n",
    "            for j in range(len(outJs)):\n",
    "                weightsInLayer[j,k] =  1 * learningRate * deltaKs[k] * outJs[j]\n",
    "        \n",
    "        gradient.insert(0, weightsInLayer)\n",
    "    return gradient\n",
    "updatedW = calcGradient(.001, alldeltas, activations, weightMatrix)\n",
    "updatedW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def updateWeights(learningRate, deltas, activations, weights):\n",
    "    #calculate the gradient\n",
    "    gradComponents = calcGradient(learningRate, deltas, activations, weights)\n",
    "    \n",
    "    #update all of the weights based on the gradient\n",
    "    newWeights = []\n",
    "    for layer in range(len(weights)):\n",
    "        weightsInLayer = weights[layer]\n",
    "        gradInLayer = gradComponents[layer]\n",
    "        \n",
    "        newWeights.append(gradInLayer + weightsInLayer)\n",
    "    return newWeights\n",
    "newWeights = updateWeights(.001, alldeltas, activations, weightMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIholGQRERGN/j9xW9EoC8o3qQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last guess:  [0.99854062 0.89082565 0.98568348 0.01825831 0.69109544 0.05949501\n",
      " 0.26903473 0.18031908 0.07529502 0.99383619]\n",
      "actual vector:  [0.21097929 0.31070097 0.5823619  0.91421451 0.76385213 0.09663155\n",
      " 0.21134969 0.0860696  0.29906261 0.31482641]\n",
      "difference:  [ 0.78756134  0.58012468  0.40332157 -0.89595619 -0.07275669 -0.03713654\n",
      "  0.05768504  0.09424948 -0.22376759  0.67900978]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3268491907760223"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trainNetwork(patterns, learningRate, neuronsPerLayer, targets):\n",
    "    #Randomly initialize all weights in network\n",
    "    weights = []\n",
    "    errors = []\n",
    "    for layer in range(len(neuronsPerLayer) - 1):\n",
    "        weights.append(np.random.randn(neuronsPerLayer[layer], neuronsPerLayer[layer + 1]))\n",
    "    \n",
    "    #Initialize error plot\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    #Loop through all input vectors, train the network, plot the error\n",
    "    for p in range(len(patterns)):\n",
    "        #forward pass through network, find all activations\n",
    "        activations, netOut = forwardprop(patterns[p], weights, neuronsPerLayer)\n",
    "        \n",
    "        #calculate deltas at output layer\n",
    "        deltaK = calcDelta(activations, targets[p])\n",
    "        \n",
    "        #calculate rest of deltas with backpropagation\n",
    "        allDeltas = backprop(activations, weights, deltaK)\n",
    "        \n",
    "        #update weights\n",
    "        weights = updateWeights(learningRate, allDeltas, activations, weights)\n",
    "        \n",
    "        #TODO: ideally(?) this should be sumOfSquareError(netOut, targets[p])\n",
    "        #calculate network error\n",
    "        error = sumOfSquareError(activations[-1], targets[p])\n",
    "        \n",
    "        #add to list of errors\n",
    "        errors.append(error)\n",
    "        \n",
    "\n",
    "    #plot the error\n",
    "    ax.plot(errors, marker= '.')\n",
    "    ax.set(xlabel = 'Iteration', ylabel= 'Sum of Squared Error', title= 'Network Error Graph')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"last guess: \", activations[-1])\n",
    "    print(\"actual vector: \", patterns[-1])\n",
    "    print(\"difference: \", (activations[-1] - patterns[-1]))\n",
    "    return error\n",
    "trainNetwork([inputVec], .001, [10, 10, 10], [targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff\n",
      "[[0.00042196 0.00052168 0.00079334 0.00112519 0.00097483 0.00030761\n",
      "  0.00042233 0.00029705 0.00051004 0.00052581]\n",
      " [0.00052168 0.0006214  0.00089306 0.00122492 0.00107455 0.00040733\n",
      "  0.00052205 0.00039677 0.00060976 0.00062553]\n",
      " [0.00079334 0.00089306 0.00116472 0.00149658 0.00134622 0.00067899\n",
      "  0.00079371 0.00066843 0.00088143 0.00089719]\n",
      " [0.00112519 0.00122492 0.00149658 0.00182843 0.00167807 0.00101085\n",
      "  0.00112557 0.00100029 0.00121328 0.00122904]\n",
      " [0.00097483 0.00107455 0.00134622 0.00167807 0.00152771 0.00086048\n",
      "  0.0009752  0.00084992 0.00106292 0.00107868]\n",
      " [0.00030761 0.00040733 0.00067899 0.00101085 0.00086048 0.00019326\n",
      "  0.00030798 0.0001827  0.0003957  0.00041146]\n",
      " [0.00042233 0.00052205 0.00079371 0.00112557 0.0009752  0.00030798\n",
      "  0.0004227  0.00029742 0.00051041 0.00052618]\n",
      " [0.00029705 0.00039677 0.00066843 0.00100029 0.00084992 0.0001827\n",
      "  0.00029742 0.00017214 0.00038513 0.0004009 ]\n",
      " [0.00051004 0.00060976 0.00088143 0.00121328 0.00106292 0.0003957\n",
      "  0.00051041 0.00038513 0.00059813 0.00061389]\n",
      " [0.00052581 0.00062553 0.00089719 0.00122904 0.00107868 0.00041146\n",
      "  0.00052618 0.0004009  0.00061389 0.00062965]]\n",
      "diff\n",
      "[[ 3.48228543e-06 -3.19838516e-05  2.26986206e-06  4.81639575e-05\n",
      "  -1.23391319e-05  1.87353753e-05  3.76022049e-05 -1.32352608e-06\n",
      "   1.89843306e-05 -2.59101411e-05]\n",
      " [ 3.42918314e-06 -1.53671014e-05 -3.44212032e-06  3.56665318e-05\n",
      "  -9.42897374e-06  1.26214426e-05  1.83795264e-05 -7.28471174e-07\n",
      "   1.43407316e-05 -1.62727966e-05]\n",
      " [ 4.19235732e-06 -2.06081840e-05 -3.56715465e-06  4.49323468e-05\n",
      "  -1.18347524e-05  1.60884322e-05  2.45755887e-05 -9.55501979e-07\n",
      "   1.80239130e-05 -2.09378725e-05]\n",
      " [ 7.48269203e-06 -2.38194033e-05 -1.09297194e-05  7.07431833e-05\n",
      "  -1.89354791e-05  2.40311324e-05  2.88750575e-05 -1.24339319e-06\n",
      "   2.86704201e-05 -2.99427715e-05]\n",
      " [ 7.67111383e-06 -2.86984362e-05 -9.69866213e-06  7.56454332e-05\n",
      "  -2.01344741e-05  2.61825655e-05  3.45500522e-05 -1.42722404e-06\n",
      "   3.05475696e-05 -3.31488443e-05]\n",
      " [ 5.83275951e-06 -2.76710851e-05 -5.31518645e-06  6.17838019e-05\n",
      "  -1.62966106e-05  2.20219558e-05  3.30344985e-05 -1.29370572e-06\n",
      "   2.48062239e-05 -2.85570771e-05]\n",
      " [ 9.54496165e-06 -2.17671992e-05 -1.69751525e-05  8.39559971e-05\n",
      "  -2.26999666e-05  2.75404966e-05  2.68697691e-05 -1.27895249e-06\n",
      "   3.42459533e-05 -3.32574782e-05]\n",
      " [ 6.89858119e-06 -2.91227221e-05 -7.55527860e-06  7.04446441e-05\n",
      "  -1.86661502e-05  2.47434701e-05  3.49029370e-05 -1.40162557e-06\n",
      "   2.83659646e-05 -3.17097535e-05]\n",
      " [ 8.70210484e-06 -2.28301265e-05 -1.44254506e-05  7.87193724e-05\n",
      "  -2.11992416e-05  2.61872163e-05  2.79485519e-05 -1.27240968e-06\n",
      "   3.20277329e-05 -3.20312078e-05]\n",
      " [ 6.70277377e-06 -1.73150562e-05 -1.12061313e-05  6.04366345e-05\n",
      "  -1.62831303e-05  2.00731470e-05  2.12153540e-05 -9.70454398e-07\n",
      "   2.45964476e-05 -2.45173604e-05]]\n",
      "diff\n",
      "[[ 2.42188374e-05  5.92530557e-06  3.24613457e-06 -2.40470381e-05\n",
      "   1.51642667e-04 -3.45561688e-07  2.03656175e-05 -9.46436960e-05\n",
      "  -3.90427985e-05 -1.30169803e-06]\n",
      " [ 1.45109320e-05  1.29520674e-05  7.18970221e-06 -1.11807004e-05\n",
      "   6.81778856e-05 -7.32465036e-07  8.97132169e-06 -4.42081420e-05\n",
      "  -1.86274448e-05 -8.24356912e-06]\n",
      " [ 1.77987477e-05  1.27535888e-06  6.67906936e-07 -1.87294695e-05\n",
      "   1.18872260e-04 -8.18768229e-08  1.60251307e-05 -7.36483220e-05\n",
      "  -3.02538008e-05  1.48780041e-06]\n",
      " [ 1.15389588e-05 -7.71509137e-06 -4.33202575e-06 -1.50744533e-05\n",
      "   9.76707760e-05  4.24279408e-07  1.33245172e-05 -5.91016094e-05\n",
      "  -2.39431110e-05  7.74551276e-06]\n",
      " [ 1.97936326e-05  1.46851334e-05  8.14355526e-06 -1.62746808e-05\n",
      "   1.00191832e-04 -8.32463862e-07  1.32621276e-05 -6.42664296e-05\n",
      "  -2.69202722e-05 -8.87728269e-06]\n",
      " [ 3.08302902e-06  4.17840219e-06  2.32334401e-06 -1.88579233e-06\n",
      "   1.10439151e-05 -2.35344703e-07  1.41583250e-06 -7.49614254e-06\n",
      "  -3.23456601e-06 -2.88393053e-06]\n",
      " [ 2.28666078e-05  4.85806500e-06  2.65409147e-06 -2.29571812e-05\n",
      "   1.44952323e-04 -2.85113860e-07  1.94815920e-05 -9.03383316e-05\n",
      "  -3.72361442e-05 -6.44423723e-07]\n",
      " [ 3.47227872e-06  4.45500513e-06  2.47669238e-06 -2.21002343e-06\n",
      "   1.30436240e-05 -2.51034424e-07  1.68082523e-06 -8.77616724e-06\n",
      "  -3.77014050e-06 -3.04883196e-06]\n",
      " [ 1.47420918e-05 -2.32339492e-06 -1.33214969e-06 -1.66731072e-05\n",
      "   1.06610753e-04  1.21058808e-07  1.44344986e-05 -6.54932576e-05\n",
      "  -2.67712225e-05  3.91528348e-06]\n",
      " [ 2.38285803e-05  5.23005371e-06  2.85924893e-06 -2.38654280e-05\n",
      "   1.50645965e-04 -3.06475380e-07  2.02435602e-05 -9.39159422e-05\n",
      "  -3.87176699e-05 -8.04594889e-07]]\n"
     ]
    }
   ],
   "source": [
    "#sanity check numerical differentiation\n",
    "\n",
    "#calculate f(x + 10**-6)\n",
    "errVec = inputVec + 10**-6\n",
    "activations1, netOut1 = forwardprop(errVec, weightMatrix, neuronsPerLayer)\n",
    "deltas1 = calcDelta(activations1, targets)\n",
    "alldeltas1 = backprop(activations1, weightMatrix, deltas1)\n",
    "updatedW1 = calcGradient(.001, alldeltas1, activations1, weightMatrix)\n",
    "\n",
    "for entry in range(len(updatedW1)):\n",
    "    #for each layer of network, return (f(x + 10**-6) - f(x)) / 10**-6\n",
    "    diff = (updatedW1[entry] - updatedW[entry])/ 10**-6\n",
    "    print(\"diff\")\n",
    "    print(diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last guess:  [1.18476149e-018 9.94012502e-010 6.38361240e-005 1.00000000e+000\n",
      " 2.06487697e-008 1.00000000e+000 5.53590570e-118 1.08008167e-020\n",
      " 1.61670495e-007 1.00000000e+000]\n",
      "actual vector:  [-0.35784792 -0.21528855 -0.15429744  0.8339397  -0.16917721  0.17873882\n",
      " -2.5710332  -0.41497714 -0.15884044  1.64184479]\n",
      "difference:  [ 0.35784792  0.21528855  0.15436128  0.1660603   0.16917723  0.82126118\n",
      "  2.5710332   0.41497714  0.1588406  -0.64184479]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.074255707417725"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test with dummy data\n",
    "num_tests = 10000\n",
    "inputData = []\n",
    "targetData = []\n",
    "\n",
    "vec = np.random.randn(10)\n",
    "#Generate data where targets are the same as the input vectors\n",
    "for test in range(num_tests):\n",
    "    inputData.append(vec)\n",
    "    targetData.append(vec)\n",
    "\n",
    "#moment of truth let's gooo\n",
    "trainNetwork(inputData, .001, [10, 10], targetData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 2.71828183, 7.3890561 ])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.array([0., 1., 2.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
