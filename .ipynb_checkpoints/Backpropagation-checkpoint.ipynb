{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation Notebook\n",
    "Design Your Own Adventure Project: QEA Spring 2018  \n",
    "Hwei-Shin Harriman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(aj):\n",
    "    #Calculates the sigmoid function using logistic\n",
    "    return 1 / (1 + np.exp(-aj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigPrime(z):\n",
    "    return (z * (1 - z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcAj(weights, prevLayerOut):    \n",
    "    #Calculates the sum of the weights and outputs from previous \n",
    "    #prevLayerOut and weights must be np arrays\n",
    "    #weights should be one ROW of the weights matrix\n",
    "    #prevLayerOut should be a ROW vector\n",
    "    return np.dot(weights, prevLayerOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#given matrix of weights, number of nodes per hidden layer,\n",
    "#and an input vector of data, propagate forward for one layer\n",
    "\n",
    "def calcLayerOutputs(inputVec, weights):\n",
    "    #define matrix of output activations for all units in current layer\n",
    "\n",
    "    return sigmoid(np.matmul(weights, inputVec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sumOfSquareError(netOutput, target):\n",
    "    #Takes 2 vectors of same dimensions, returns the sum-of-squares error\n",
    "    return 0.5 * np.sum(np.power(netOutput - target, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcDelta(netOutput, target):\n",
    "    #Takes 2 np arrays, all activations from forward prop and actual target\n",
    "    #returns delta value for each output neuron\n",
    "    #assumes netOutput's last entry is activations of output layer\n",
    "    sigOutk = []\n",
    "    guesses = netOutput[-1]\n",
    "    for k in range(len(guesses)):\n",
    "        sigOutk.append(sigPrime(guesses[k]))\n",
    "    return np.asarray(sigOutk) * (guesses - target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#neuronsPerLayer = array with number of neurons in each hidden/output layer\n",
    "def forwardprop(inputVec, weights):\n",
    "    #calculates outputs for all neurons in network\n",
    "    activations = [inputVec]\n",
    "    \n",
    "    #dynamically calculates activations for all nodes in network\n",
    "    for layer in range(len(weights)):\n",
    "        weightsInLayer = weights[layer]\n",
    "        \n",
    "        #calculates all activations for current layer\n",
    "        layerActivations = calcLayerOutputs(activations[layer], weightsInLayer[:, :])\n",
    "            \n",
    "        #adds resulting np array to list\n",
    "        activations.append(layerActivations)\n",
    "    #should be number of layers * j (neurons per layer) activations\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprop(activations, weights, deltaK):\n",
    "    #calculates deltas for hidden units\n",
    "    allDeltas = [deltaK]\n",
    "    for layer in range(len(weights) - 1, 0, -1):\n",
    "        #fetches activations from previous layer\n",
    "        zj = activations[layer - 1]\n",
    "        weightsInLayer = weights[layer]\n",
    "        \n",
    "        #empty cache list\n",
    "        deltaJs = []\n",
    "        for j in range(len(zj)):\n",
    "            dj = sigPrime(zj[j]) * np.dot(weightsInLayer[j, :], allDeltas[0])\n",
    "            deltaJs.append(dj)\n",
    "        \n",
    "        #builds list of deltas to have same indexing as weights matrix\n",
    "        allDeltas.insert(0, np.asarray(deltaJs))\n",
    "        \n",
    "    #inserts placeholder activations on input vecs for indexing in\n",
    "    #updateWeights function\n",
    "    allDeltas.insert(0, activations[0])\n",
    "    return allDeltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.18864487, 0.60525718, 0.36171265, 0.96860732, 0.31090988,\n",
      "       0.7696819 , 0.04664802, 0.5498162 , 0.50742133, 0.91485144]), array([0.39821585, 0.38416265, 0.99639702, 0.29996002, 0.87815462,\n",
      "       0.02907887, 0.74005026, 0.20161136, 0.78564119, 0.5606162 ]), array([0.53894121, 0.48833801, 0.8721735 , 0.01709679, 0.39244402,\n",
      "       0.52605792, 0.95479675, 0.98930578, 0.54227072, 0.9173345 ]), array([0.94721622, 0.69959202, 0.77322195, 0.59051607, 0.15868053,\n",
      "       0.62492334, 0.23040174, 0.2858955 , 0.52877923, 0.72609816])]\n"
     ]
    }
   ],
   "source": [
    "#testing functionality of forward propagation\n",
    "\n",
    "#generate random vector and weight matrix\n",
    "inputVec = np.random.rand(10)\n",
    "numLayers = 3\n",
    "weightMatrix = []\n",
    "for layer in range(numLayers):\n",
    "    weightMatrix.append(np.random.randn(10, 10))\n",
    "neuronsPerLayer = [10, 10, 10]\n",
    "activations = forwardprop(inputVec, weightMatrix)\n",
    "\n",
    "#first entry of activations is the input vector\n",
    "print(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04735858,  0.14702838,  0.13558429, -0.09901602, -0.11231701,\n",
       "       -0.08791578,  0.04085409,  0.05836821, -0.11741491,  0.14440613])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test functionality of deltas function\n",
    "targets = np.array([0., 0., 0., 1., 1., 1. , 0., 0., 1., 0.])\n",
    "\n",
    "deltas = calcDelta(activations, targets)\n",
    "deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.18864487, 0.60525718, 0.36171265, 0.96860732, 0.31090988,\n",
       "        0.7696819 , 0.04664802, 0.5498162 , 0.50742133, 0.91485144]),\n",
       " array([-0.06742865, -0.00555028, -0.02718255,  0.00642423, -0.03628137,\n",
       "         0.00836004, -0.00983969, -0.01807249, -0.04063305, -0.01065748]),\n",
       " array([-0.09186496, -0.02371459, -0.000497  , -0.03473956,  0.00378769,\n",
       "         0.00660783, -0.07175188,  0.06372241, -0.00084253, -0.11808505]),\n",
       " array([ 0.04735858,  0.14702838,  0.13558429, -0.09901602, -0.11231701,\n",
       "        -0.08791578,  0.04085409,  0.05836821, -0.11741491,  0.14440613])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test functionality of backprop\n",
    "alldeltas = backprop(activations, weightMatrix, deltas)\n",
    "alldeltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[3.55868858e-05, 1.14178660e-04, 6.82352342e-05, 1.82722798e-04,\n",
       "         5.86515525e-05, 1.45196540e-04, 8.79990976e-06, 1.03720003e-04,\n",
       "         9.57224284e-05, 1.72582028e-04],\n",
       "        [1.14178660e-04, 3.66336250e-04, 2.18929176e-04, 5.86256529e-04,\n",
       "         1.88180435e-04, 4.65855495e-04, 2.82340496e-05, 3.32780198e-04,\n",
       "         3.07120399e-04, 5.53720400e-04],\n",
       "        [6.82352342e-05, 2.18929176e-04, 1.30836039e-04, 3.50357516e-04,\n",
       "         1.12460035e-04, 2.78403678e-04, 1.68731793e-05, 1.98875472e-04,\n",
       "         1.83540711e-04, 3.30913337e-04],\n",
       "        [1.82722798e-04, 5.86256529e-04, 3.50357516e-04, 9.38200132e-04,\n",
       "         3.01149582e-04, 7.45519521e-04, 4.51836146e-05, 5.32555989e-04,\n",
       "         4.91492008e-04, 8.86131799e-04],\n",
       "        [5.86515525e-05, 1.88180435e-04, 1.12460035e-04, 3.01149582e-04,\n",
       "         9.66649519e-05, 2.39301706e-04, 1.45033306e-05, 1.70943286e-04,\n",
       "         1.57762302e-04, 2.84436350e-04],\n",
       "        [1.45196540e-04, 4.65855495e-04, 2.78403678e-04, 7.45519521e-04,\n",
       "         2.39301706e-04, 5.92410230e-04, 3.59041377e-05, 4.23183575e-04,\n",
       "         3.90553011e-04, 7.04144597e-04],\n",
       "        [8.79990976e-06, 2.82340496e-05, 1.68731793e-05, 4.51836146e-05,\n",
       "         1.45033306e-05, 3.59041377e-05, 2.17603789e-06, 2.56478376e-05,\n",
       "         2.36702008e-05, 4.26760095e-05],\n",
       "        [1.03720003e-04, 3.32780198e-04, 1.98875472e-04, 5.32555989e-04,\n",
       "         1.70943286e-04, 4.23183575e-04, 2.56478376e-05, 3.02297849e-04,\n",
       "         2.78988463e-04, 5.03000139e-04],\n",
       "        [9.57224284e-05, 3.07120399e-04, 1.83540711e-04, 4.91492008e-04,\n",
       "         1.57762302e-04, 3.90553011e-04, 2.36702008e-05, 2.78988463e-04,\n",
       "         2.57476401e-04, 4.64215131e-04],\n",
       "        [1.72582028e-04, 5.53720400e-04, 3.30913337e-04, 8.86131799e-04,\n",
       "         2.84436350e-04, 7.04144597e-04, 4.26760095e-05, 5.03000139e-04,\n",
       "         4.64215131e-04, 8.36953160e-04]]),\n",
       " array([[-2.68511563e-05, -2.21020954e-06, -1.08245210e-05,\n",
       "          2.55822964e-06, -1.44478168e-05,  3.32909875e-06,\n",
       "         -3.91832092e-06, -7.19675339e-06, -1.61807259e-05,\n",
       "         -4.24397841e-06],\n",
       "        [-2.59035686e-05, -2.13221040e-06, -1.04425195e-05,\n",
       "          2.46794873e-06, -1.39379478e-05,  3.21161357e-06,\n",
       "         -3.78004186e-06, -6.94277718e-06, -1.56097019e-05,\n",
       "         -4.09420677e-06],\n",
       "        [-6.71857048e-05, -5.53028273e-06, -2.70846092e-05,\n",
       "          6.40108229e-06, -3.61506500e-05,  8.32991486e-06,\n",
       "         -9.80423895e-06, -1.80073790e-05, -4.04866540e-05,\n",
       "         -1.06190839e-05],\n",
       "        [-2.02258988e-05, -1.66486217e-06, -8.15367741e-06,\n",
       "          1.92701175e-06, -1.08829607e-05,  2.50767652e-06,\n",
       "         -2.95151394e-06, -5.42102559e-06, -1.21882917e-05,\n",
       "         -3.19681867e-06],\n",
       "        [-5.92127796e-05, -4.87400427e-06, -2.38704796e-05,\n",
       "          5.64146608e-06, -3.18606536e-05,  7.34140416e-06,\n",
       "         -8.64077025e-06, -1.58704440e-05, -3.56821042e-05,\n",
       "         -9.35891755e-06],\n",
       "        [-1.96074900e-06, -1.61395886e-07, -7.90437797e-07,\n",
       "          1.86809319e-07, -1.05502132e-06,  2.43100408e-07,\n",
       "         -2.86127113e-07, -5.25527723e-07, -1.18156335e-06,\n",
       "         -3.09907564e-07],\n",
       "        [-4.99005888e-05, -4.10748633e-06, -2.01164511e-05,\n",
       "          4.75425205e-06, -2.68500379e-05,  6.18684670e-06,\n",
       "         -7.28186594e-06, -1.33745537e-05, -3.00705020e-05,\n",
       "         -7.88707268e-06],\n",
       "        [-1.35943813e-05, -1.11899953e-06, -5.48031023e-06,\n",
       "          1.29519745e-06, -7.31473641e-06,  1.68547817e-06,\n",
       "         -1.98379348e-06, -3.64361999e-06, -8.19208514e-06,\n",
       "         -2.14866951e-06],\n",
       "        [-5.29747235e-05, -4.36052877e-06, -2.13557287e-05,\n",
       "          5.04713861e-06, -2.85041393e-05,  6.56798850e-06,\n",
       "         -7.73046661e-06, -1.41984955e-05, -3.19230007e-05,\n",
       "         -8.37295721e-06],\n",
       "        [-3.78015931e-05, -3.11157705e-06, -1.52389765e-05,\n",
       "          3.60152667e-06, -2.03399244e-05,  4.68677158e-06,\n",
       "         -5.51629029e-06, -1.01317329e-05, -2.27795485e-05,\n",
       "         -5.97475740e-06]]),\n",
       " array([[-4.95098143e-05, -1.27807699e-05, -2.67854626e-07,\n",
       "         -1.87225791e-05,  2.04134119e-06,  3.56122965e-06,\n",
       "         -3.86700444e-05,  3.43426336e-05, -4.54071847e-07,\n",
       "         -6.36408973e-05],\n",
       "        [-4.48611535e-05, -1.15807358e-05, -2.42704758e-07,\n",
       "         -1.69646464e-05,  1.84967206e-06,  3.22685254e-06,\n",
       "         -3.50391699e-05,  3.11180758e-05, -4.11437351e-07,\n",
       "         -5.76654164e-05],\n",
       "        [-8.01221864e-05, -2.06832372e-05, -4.33471597e-07,\n",
       "         -3.02989214e-05,  3.30352117e-06,  5.76317060e-06,\n",
       "         -6.25800874e-05,  5.55769988e-05, -7.34828634e-07,\n",
       "         -1.02990648e-04],\n",
       "        [-1.57059614e-06, -4.05443410e-07, -8.49713231e-09,\n",
       "         -5.93934979e-07,  6.47573142e-08,  1.12972622e-07,\n",
       "         -1.22672693e-06,  1.08944880e-06, -1.44044873e-08,\n",
       "         -2.01887543e-06],\n",
       "        [-3.60518555e-05, -9.30664913e-06, -1.95045294e-07,\n",
       "         -1.36333316e-05,  1.48645554e-06,  2.59320174e-06,\n",
       "         -2.81585958e-05,  2.50074794e-05, -3.30644193e-07,\n",
       "         -4.63417701e-05],\n",
       "        [-4.83262911e-05, -1.24752479e-05, -2.61451610e-07,\n",
       "         -1.82750192e-05,  1.99254330e-06,  3.47609910e-06,\n",
       "         -3.77456440e-05,  3.35216791e-05, -4.43217342e-07,\n",
       "         -6.21195731e-05],\n",
       "        [-8.77123679e-05, -2.26426136e-05, -4.74535480e-07,\n",
       "         -3.31692164e-05,  3.61647225e-06,  6.30913062e-06,\n",
       "         -6.85084606e-05,  6.08419513e-05, -8.04440847e-07,\n",
       "         -1.12747217e-04],\n",
       "        [-9.08825384e-05, -2.34609810e-05, -4.91686521e-07,\n",
       "         -3.43680447e-05,  3.74718168e-06,  6.53716026e-06,\n",
       "         -7.09845481e-05,  6.30409498e-05, -8.33515591e-07,\n",
       "         -1.16822217e-04],\n",
       "        [-4.98156793e-05, -1.28597278e-05, -2.69509396e-07,\n",
       "         -1.88382447e-05,  2.05395232e-06,  3.58323045e-06,\n",
       "         -3.89089427e-05,  3.45547978e-05, -4.56877043e-07,\n",
       "         -6.40340622e-05],\n",
       "        [-8.42708997e-05, -2.17542117e-05, -4.55916684e-07,\n",
       "         -3.18677944e-05,  3.47457693e-06,  6.06158660e-06,\n",
       "         -6.58204738e-05,  5.84547664e-05, -7.72877937e-07,\n",
       "         -1.08323486e-04]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calcGradient(learningRate, deltas, activations, weights):\n",
    "    #for each layer, for each weight @ every node, calculate the gradient\n",
    "    gradient = []\n",
    "    for layer in range(len(weights) -1, -1, -1):\n",
    "        deltaKs = deltas[layer]\n",
    "        outJs = activations[layer]\n",
    "        weightDims = weights[layer]\n",
    "        \n",
    "        #pre-allocate array to fill with gradient values\n",
    "        weightsInLayer = np.array([[0.] * weightDims.shape[0]] * weightDims.shape[1])\n",
    "\n",
    "        for k in range(len(deltaKs)):\n",
    "            for j in range(len(outJs)):\n",
    "                weightsInLayer[j,k] =  1 * learningRate * deltaKs[k] * outJs[j]\n",
    "        \n",
    "        gradient.insert(0, weightsInLayer)\n",
    "    return gradient\n",
    "updatedW = calcGradient(.001, alldeltas, activations, weightMatrix)\n",
    "updatedW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def updateWeights(learningRate, deltas, activations, weights):\n",
    "    #calculate the gradient\n",
    "    gradComponents = calcGradient(learningRate, deltas, activations, weights)\n",
    "    \n",
    "    #update all of the weights based on the gradient\n",
    "    newWeights = []\n",
    "    for layer in range(len(weights)):\n",
    "        weightsInLayer = weights[layer]\n",
    "        gradInLayer = gradComponents[layer]\n",
    "        \n",
    "        newWeights.append(gradInLayer + weightsInLayer)\n",
    "    return newWeights\n",
    "newWeights = updateWeights(.001, alldeltas, activations, weightMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last guess:  [0.44804891 0.46100662 0.88782868 0.4710864  0.82330092 0.36967229\n",
      " 0.28424996 0.06632339 0.08483984 0.72758277]\n",
      "actual vector:  [0.18864487 0.60525718 0.36171265 0.96860732 0.31090988 0.7696819\n",
      " 0.04664802 0.5498162  0.50742133 0.91485144]\n",
      "difference:  [ 0.25940405 -0.14425055  0.52611603 -0.49752091  0.51239104 -0.40000961\n",
      "  0.23760194 -0.4834928  -0.42258149 -0.18726867]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6809457605242792"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trainNetwork(patterns, learningRate, neuronsPerLayer, targets):\n",
    "    #Randomly initialize all weights in network\n",
    "    weights = []\n",
    "    errors = []\n",
    "    for layer in range(len(neuronsPerLayer) - 1):\n",
    "        weights.append(np.random.randn(neuronsPerLayer[layer], neuronsPerLayer[layer + 1]))\n",
    "    \n",
    "    #Initialize error plot\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    #Loop through all input vectors, train the network, plot the error\n",
    "    for p in range(len(patterns)):\n",
    "        #forward pass through network, find all activations\n",
    "        activations = forwardprop(patterns[p], weights)\n",
    "        \n",
    "        #calculate deltas at output layer\n",
    "        deltaK = calcDelta(activations, targets[p])\n",
    "        \n",
    "        #calculate rest of deltas with backpropagation\n",
    "        allDeltas = backprop(activations, weights, deltaK)\n",
    "        \n",
    "        #update weights\n",
    "        weights = updateWeights(learningRate, allDeltas, activations, weights)\n",
    "        \n",
    "        #TODO: ideally(?) this should be sumOfSquareError(netOut, targets[p])\n",
    "        #calculate network error\n",
    "        error = sumOfSquareError(activations[-1], targets[p])\n",
    "        \n",
    "        #add to list of errors\n",
    "        errors.append(error)\n",
    "        \n",
    "\n",
    "    #plot the error\n",
    "    ax.plot(errors, marker= '.')\n",
    "    ax.set(xlabel = 'Iteration', ylabel= 'Sum of Squared Error', title= 'Network Error Graph')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"last guess: \", activations[-1])\n",
    "    print(\"actual vector: \", patterns[-1])\n",
    "    print(\"difference: \", (activations[-1] - patterns[-1]))\n",
    "    return error\n",
    "trainNetwork([inputVec], .001, [10, 10, 10], [targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHm9JREFUeJzt3XucHHWZ7/HPd2YSwiUxBKKLxhBQ\nRBAlkChXFRRBEZUXImLwhrpxvbCyKwfD0RX0rHtwVY6yuiJHwdUFRFFAEGRZ5KLsimQEQhRiuAXC\nNZFLEgiQmXn2j/qN9PT09NTMdHVPd33fr1e/pupXNVVPTSXP1Dz1q18pIjAzs87X1eoAzMysOZzw\nzcxKwgnfzKwknPDNzErCCd/MrCSc8M3MSsIJ3zqapGskfaTVcUx2ku6RdFCr47BiOeHbmKXk8LCk\nLSvaPiLpmpzf/31J/1hYgOOUjmujpA0Vn2+2II7pkk5L8Twp6V5JF0h6TbNjsc7ihG/j1QN8qtVB\njESZ8fz7fltEbFXx+eQI2+/J0zZKjLW2sRnwK+CVwGHADGAX4EfAoXm3Y1aLE76N11eAEyTNrLVQ\n0sslXSnpUUkrJB2V2hcDxwAnpivoSyQdK+mSiu+9Q9KPK+bvkzQ/Te8r6UZJT6Sv+1asd42kL0m6\nHngK2LEqpu0kLZN0wlgPVtIHJV0v6f9JehQ4ZYS2Lkmfk7RK0iOSfiDpeWkb8ySFpA9LupcssVd7\nHzAHODwilkdEf0Q8GREXRMQpFfGEpE9IWgmsTG3fSD+rdZJ6Jb22Yv1T0l8J50taL+n3knav2vf8\n9PN5Iq03baw/J5vcnPBtvJYC1wDDkmcq9VwJnAs8H3gP8K+SXhERZwLnAP+crqDfBlwLvDYly+2A\nKcB+aVs7AlsByyTNAn4BnA5sA5wG/ELSNhW7fx+wGJgOrKqIaV7azzcj4qvjPOa9gLvSMX1phLYP\nps+BZL9wtgKqy0KvJ7tqP6TGPg4CroiIJ3PEc3ja/65p/kZgPjCL7Gf/k6qk/Q7gJxXLL5I0pWL5\nUcCbgR2AV6XjsA7ihG8T8XngOEmzq9oPA+6JiLMjoi8ifg/8FDiy1kYi4i5gPVmyej1wBXC/pJen\n+V9HxADwVmBlRPwwbfc84HbgbRWb+35E/CEt35TadiX75XRy+oVTz0WSHq/4/HXFsgci4l/StjeO\n0HYMcFpE3BURG4CTgKOryi6npKv2jQy3LfDQ4Iyk+SmOdZJWVK37fyPi0cHtRMS/R8SfUyxfAzYD\ndq5Yvzf9pbCJ7JflNGDviuWnR8QDEfEocAnZ+bAO4tqfjVtELJd0KbAEuK1i0fbAXpIer2jrAX5Y\nZ3PXAgcAL03Tj5Ml+33SPMALqbhqT1YBL6qYv6/Gto8B7gAuqLP/QYdHxH+OsKzWtqvbqmNcRXbs\nLxhlO4P+DGw3OBMRNwMzUw+a79bbt6RPAx9JMQRZ/X/bWutHxICk1WndQQ9VTD9Vtcw6gK/wbaJO\nBv6a4Un32oiYWfHZKiI+lpbXGqJ1MOG/Nk1fS5bwX89zCf8Bsl8mleYC91fM19r2KcBa4FxJ3TmP\nq5Za265uq45xLtAHPDzKdgZdBRxc2QMqTzypXv8ZsrLM1hExE3gCUMX6L65Yv4vsXsEDOfZjHcIJ\n3yYkIu4Azgf+tqL5UuBlkt4naUr6vFrSLmn5w1TdUCVL6gcCm0fEauDXZPXkbYCb0jqXpe0uktQj\n6d1k5ZpLRwlzE/AuYEvgh+PsvZPXecDfSdpB0lbAPwHnR0Rfzu//AfAgcKGk3SR1pzr8wlG+bzrZ\nL5Y1QI+kz5Nd4VdaIOmIVF46HngG+G3OuKwDOOFbI3yRLJkCEBHrgYOBo8muIB8CvkxWUwb4HrBr\nqk1flL7nT8AGskRPRKwjuxl6fUT0p7Y/k90f+DRZ6eNE4LCIWDtagBHxLHAE2c3Vs+ok/Us0tB/+\nhfl/DACcRVa6ug64G3gaOC7vN0fE02S/+P5IdoN6HbACeDXZ1ftIrgAuB/5EVkZ6muGlo4uBdwOP\nkd3cPqLiPoeVgPwCFLPOJ+kU4KUR8d5Wx2Kt4yt8M7OScMI3MysJl3TMzErCV/hmZiUxqR682nbb\nbWPevHmtDsPMrG309vaujYjqp91rmlQJf968eSxdurTVYZiZtQ1J1U+fj8glHTOzknDCNzMrCSd8\nM7OScMI3MysJJ3wzs5JwwjczK4mOSPi9qx7jW1ffQe+qx1odipnZpDWp+uGPR+89j/KuM/6bAaCn\nC87/6L4s2H7rVodlZjbptP0V/hnX3cVAmu4bgDOuvbOl8ZiZTVZtn/D/+MATdefNzCzT9gl/w7N9\ndefNzCzT9gl/U1/UnTczs0zbJ/yp3ao7b2ZmmbZP+D09XXXnzcws0/bZcVP/QN15MzPLtH/Cdw3f\nzCyXtk/4ruGbmeXT9gm/uma/acBX+GZmtbR9wt+sp3vI/JPP9HPuDfe2KBozs8mr7RP+K7abMazt\nrN/c1YJIzMwmt7ZP+B99/UuGtT3+9KYWRGJmNrm1fcJfsP3WbDl1aFnHXTPNzIZr+4QPUH2b1l0z\nzcyG64iE766ZZmaj64iEH6o/b2ZmHZLw/bStmdnoOiLhVx9ERxyUmVmDdURurO6T4z46ZmbDdUTC\n9xW+mdnoOiI3+grfzGx0HZHwfYVvZja6jsiN1Vf0G/v6WxKHmdlk1hEJf9YWU4bM9w/AqZfd1qJo\nzMwmp8ISvqSdJd1c8Vkn6fgi9vXxA3ca1vbjpfcVsSszs7ZVWMKPiBURMT8i5gMLgKeAC4vY16K9\n5g4bTuHZPt+6NTOr1KySzhuBOyNiVVE7kIYmfL/5ysxsqGYl/KOB82otkLRY0lJJS9esWdOkcMzM\nyqfwhC9pKvB24Ce1lkfEmRGxMCIWzp49e9z7mdKluvNmZmXXjCv8twC/j4iHi9xJdQnHJR0zs6Ga\nkfDfwwjlHDMza55CE76kLYA3AT8rcj/gko6Z2Wh6itx4RDwFbFPkPga5pGNmVl9HPGkLMBBDE3zf\ngPvhm5lV6piE31XVD79/AHpXPdaiaMzMJp+OSfizt5o6rO2Ma+9sQSRmZpNTxyT8WuPp3HSvr/DN\nzAZ1TMJftNdcuquOZv3Tfa0JxsxsEuqYhA/D6/jVN3LNzMqsoxK+mZmNzAnfzKwknPDNzErCCd/M\nrCQ6KuFX36T1TVszs+d0VMKvzu8eXcHM7DkdlfB7qkbIDDy8gpnZoLoJX1K3pK80K5iJev70zYa1\nnXr5bS2IxMxs8qmb8COiH1ig6jeET1K1hlf4w/1PtCASM7PJJ09J5ybgYknvk3TE4KfowMZj0V5z\nhx3QM/0u5JuZQb4XoMwC/gy8oaItaMJbrMZFZNEl7qhjZpYZNeFHxLHNCKRRugSVL7vymw7NzDKj\nlnQkzZF0oaRHJD0s6aeS5jQjuPGovt3QJrcfzMwKl6eGfzbwc+CFwIuAS1LbpOSHr8zMasuT8GdH\nxNkR0Zc+3wdmFxzXuFXnd+d7M7NMnoS/VtJ7U5/8bknvJbuJOylV1+xd0DEzy+RJ+B8CjgIeAh4E\njkxtk1J1zb4//LStmRnkeNIWeGdEvD0iZkfE8yPi8IhY1aT4xmzzKd3D2vy0rZlZvidt39GkWBpi\n0WvmDmvz07ZmZvlKOtdL+qak10rac/BTeGTjtOTQXYbV7f20rZlZvidt901fv1jRFgx98nZSkYb2\nznFPHTOzURK+pC7g2xHx4ybF0xB+2tbMbLjRavgDwCebFEvDVF/Q+wLfzCxfDf9KSSdIerGkWYOf\nwiObAD98ZWY2XJ4a/mCf+09UtAWwY+PDaYzqCo4rOmZm+UbL3KEZgTRS9QX9gK/wzcxGLulIOrFi\n+l1Vy/4pz8YlzZR0gaTbJd0maZ/xh5qf321rZjZcvRr+0RXTJ1Ute3PO7X8D+GVEvBzYHWjKI69+\nt62Z2XD1Er5GmK41P/ybpRnA64DvAUTEsxHx+JgjHIda77Zddl9Tdm1mNmnVS/gxwnSt+Vp2BNYA\nZ0u6SdJ3JW051gDHY9Few4dX2ORCvpmVXL2Ev7ukdZLWA69K04Pzr8yx7R5gT7IHt/YAngSWVK8k\nabGkpZKWrlmzZjzHUHvnVUfmh6/MrOxGTPgR0R0RMyJiekT0pOnB+Sk5tr0aWB0RN6T5C8h+AVTv\n58yIWBgRC2fPbtx7VfzwlZnZUHkevBqXiHgIuE/SzqnpjcAfi9rf8P3XnzczK5s8D15NxHHAOZKm\nAncBxxa8v7/weDpmZkMVmvAj4mZgYZH7GEn25quomjczK6/CSjpmZja5jHiFn3rjjFj5jogZhURU\nkE39LuKbWbnV66UzPSX1r5N1p3wRMAf4DPCPzQlv/Gq92/b4H93UgkjMzCaHPCWdQyLiXyNifUSs\ni4hvA+8sOrCJqvVu28tufbAFkZiZTQ55En6/pGMkdUvqknQM0F90YBNV6922A+6baWYllifhLwKO\nAh5On3eltkmvp3toyndPHTMrszzj4d8DvKP4UMzMrEijXuFLepmkqyQtT/OvkvS54kMzM7NGylPS\n+f9k4+FvAoiIZQwdK9/MzNpAnoS/RUT8rqqtr4hgzMysOHkS/lpJLyE9hCXpSMD9G83M2kyesXQ+\nAZwJvFzS/cDdwDGFRtUgXVXj6XS5l46ZlVjdhC+pC1gYEQelt1V1RcT65oQ2cVO6xDMV8/0DAy2L\nxcys1eqWdCJiAPhkmn6ynZI9wNSq4RX6BuDUy/wyczMrpzw1/CslnSDpxZJmDX4Kj6wBjlowZ1jb\nOTesakEkZmatlyfhf4isjn8d0Js+S4sMqlFqDa/wdJ/LOmZWTnmetN2hGYEUpadbHhrZzIycb7yS\ntBuwKzBtsC0iflBUUI3knjpmZplRE76kk4EDyBL+ZcBbgN8AbZHwq3vqTPHLbc2spPLU8I8E3gg8\nFBHHArsDmxUaVQNtGoi682ZmZZEn4W9M3TP7JM0AHgF2LDasxqkeA99j4ptZWeWp4S+VNJNsELVe\nYANQPbbOpOUavplZJk8vnY+nyTMk/RKYkUbMbAuu4ZuZZfLctH1drbaIuK6YkBrLNXwzs0yeks7/\nqpieBryGrLTzhkIiKtimfj94ZWblNOpN24h4W8XnTcBuZO+2bQuzt5o6ZH4gPJ6OmZVTnl461VaT\nJf228PEDdxrW5vF0zKyM8tTw/4Xnurl0AfOBW4oMqpEW7TWXf7j4ViorOc96qAUzK6Fc3TIrpvuA\n8yLi+oLiKcTmPd1seLb/L/PuqWNmZZSnW+a/NSOQIrmnjplZvpLOrVQ+uVSxCIiIeFXDozIzs4bL\nU9K5PH39Yfp6DPAU0DZX/n74yswsX8LfLyL2q5hfIun6iPhiUUE1WnXPe/fEN7MyypPwt5S0f0T8\nBkDSvsCWeTYu6R5gPdAP9EXEwvEGOhHVfU/H0xfVzKzd5Un4HwbOkvS8NP842WsP8zowItaOObIG\n8hW+mVm+Xjq9wO5paGRFxBPFh9VYvsI3M6uT+yS9TdL2FU3HA9dJ+rmkvO+5DeA/JPVKWjzCfhZL\nWipp6Zo1a/JHPgbV3TA39vWPsKaZWeeqd7H7JWANgKTDgPeSlXJ+DpyRc/v7RcSeZK9F/EStkTcj\n4syIWBgRC2fPnj2m4PParGfoYfYPwLk33FvIvszMJqt6CT8i4qk0fQTwvYjojYjvArkyc0Q8kL4+\nAlxINtJm0y16zdxhbd+6emULIjEza516CV+StpLURfZO26sqlk0bbcOStpQ0fXAaOBhYPpFgx2vJ\nobvQXXWkjz21qRWhmJm1TL2btl8HbgbWAbdFxFIASXsAD+bY9guAC5W9UrAHODcifjmxcMdvWk83\nT1aMp+Mbt2ZWNiMm/Ig4S9IVwPMZOjrmQ8Cxo204Iu4Cdp9whA1SPTaEu2aaWdnU7ZYZEfcD91e1\n5bm6n3TcNdPMyq40ec8PX5lZ2dXrh5+3r31b8BW+mZVdvbx3AYCkq+qs0zZ8hW9mZVevht8l6WTg\nZZL+vnphRJxWXFiN5yt8Myu7ennvaOBpsl8K02t82oqv8M2s7Op1y1wBfFnSsoi4fKT12oWv8M2s\n7PLkvf+SdNrgAGeSvlYxVHLb8ABqZlZ2eRL+WWQvMTkqfdYBZxcZVBE8gJqZlV2ehP+SiDg5Iu5K\nny8AOxYdWKN5ADUzK7s8CX+jpP0HZyTtB2wsLqRiLDl0F3o8gJqZlVieVxz+DfCDirr9Y8AHigup\nONN6utngAdTMrKTyvOLwFp57xSERsa7wqArirplmVmZ5rvCB9k70g9w108zKrFQ5r7prZvW8mVkn\nK1XCNzMrs1FLOpK6gbcC8yrXb7exdACmdIlnqubNzMoiTw3/ErIxdW6lze9zuqRjZmWWJ+HPiYhX\nFR6JmZkVKk8N/3JJBxceSRNUl3B8A8PMyiRPzvstcKGkjZLWSVovqS27aFbXozb2DdC76rGWxGJm\n1mx5Ev7XgH2ALSJiRkRMj4gZBcdViFlbTBnWdsa1d7YgEjOz5suT8FcCyyOi7e9wfvzAnYa13XSv\nr/DNrBzy3LR9ELhG0uXwXK/GduyWuWivuXz+4lvpq6jtrH+6r3UBmZk1UZ6Ef3f6TE2ftiYJeO6P\nlYH2/8PFzCyXPIOnfaEZgTRLV1XCz+bNzDpfnidtr6YyQyYR8YZCIiqYn7Y1s7LKU9I5oWJ6GvBO\noG0L337a1szKKk9Jp7eq6XpJ1xYUT+Gqa/au4ZtZWeQp6cyqmO0CFgB/VVhEZmZWiDwlnV6yGr7I\nSjl3Ax8uMigzM2u8PCWdHZoRSKv0u4ZvZiUx4pO2kl4t6a8q5t8v6WJJp1eVedrKlO6hhzwQcO4N\n97YoGjOz5qk3tMJ3gGcBJL0OOBX4AfAEcGbeHUjqlnSTpEsnEmij7PbC4cMAfevqlS2IxMysueol\n/O6IeDRNvxs4MyJ+GhH/ALx0DPv4FHDbeANstM+8ZZdhbWs3PNuCSMzMmqtuwpc0WON/I/CrimV5\nbvYiaQ7Z6xG/O77wGm/B9lvTU3XU7pppZmVQL3GfB1wraS2wEfg1gKSXkpV18vg6cCIwfaQVJC0G\nFgPMnTs352Ynpno8HTOzMhjxCj8ivgR8Gvg+sH/F8MhdwHGjbVjSYcAjNR7cqt7PmRGxMCIWzp49\nO3fgZmY2NnVLMxHx2xptf8q57f2At0s6lGxIhhmS/j0i3jv2MBvLT9uaWRkV9lrXiDgpIuZExDzg\naOBXkyHZA1Tnd+d7MyuDUr7Hu3qATA+YaWZlkKu3zURFxDXANc3YVx7VF/R+2NbMyqCUV/jVBgJ6\nV/ndtmbW2UqZ8LfZcvibGj934a0tiMTMrHlKmfCPP2jnYW1/enh9CyIxM2ueUib8RXsNf8DLdXwz\n63SlTPgA3e6pY2YlU9qEX31F7yt8M+t0pU341fnd+d7MOl1pE76ZWdk44ZuZlURpE353jSM//kc3\nNT8QM7MmKW3C3/kFw4fov3TZAy2IxMysOUqb8P/P4a8c1tY30IJAzMyapLQJf8H2W7c6BDOzpipt\nwjczKxsnfDOzknDCNzMriVIn/FrD57z/ezc0PQ4zs2YodcLffpsthrX9euXaFkRiZla8Uif8rx01\nf1ibx9Qxs05V6oTvrplmVialTvhmZmXihF+Dx9Qxs05U+oQ/pcarri6+2WPqmFnnKX3C//D+Owxr\n841bM+tEpU/4Sw7dpdUhmJk1RekT/khOvey2VodgZtZQTvgj+M51d7U6BDOzhnLCB+bPed6wNtfx\nzazTOOEDF31y/1aHYGZWOCf8Ol722ctaHYKZWcM44SdbTe0e1vZsvws7ZtY5nPCT5V98c832+V+4\nosmRmJkVo7CEL2mapN9JukXSHyR9oah9FenxjX2tDsHMrCGKvMJ/BnhDROwOzAfeLGnvAvc3YbV6\n6wDMW/KLJkdiZtZ4hSX8yGxIs1PSZ1IXxev11nHSN7N2V2gNX1K3pJuBR4ArI2LSvz/w8PkvHHHZ\nvCW/cOI3s7aliOIvuiXNBC4EjouI5VXLFgOLAebOnbtg1apVhcczmvEk9XtOfWsBkZiZ1SepNyIW\n5lq3GQkfQNLJwJMR8dWR1lm4cGEsXbq0KfGMxlfyZtZs47lwHEvCL7KXzux0ZY+kzYGDgNuL2l+j\n+YrdzJqt6AvNImv42wFXS1oG3EhWw7+0wP013D2nvpWZm/e0Ogwzs4YoLJtFxDJgj6K23yw3n3wI\nALt9/pdseLa/xdGYmY2fL19zqvUk7pu+dg0r1zzZgmjMrBMVXUp2wp+AKz99QKtDMDPLzWPpmJmV\nhBO+mVlJOOGbmZWEE76ZWUk44ZuZlYQTvplZSTRtLJ08JK0Bxjt62rbA2gaG0w58zJ2vbMcLPuax\n2j4iZudZcVIl/ImQtDTvAEKdwsfc+cp2vOBjLpJLOmZmJeGEb2ZWEp2U8M9sdQAt4GPufGU7XvAx\nF6ZjavhmZlZfJ13hm5lZHU74ZmYl0fYJX9KbJa2QdIekJa2OZyIkvVjS1ZJuk/QHSZ9K7bMkXSlp\nZfq6dWqXpNPTsS+TtGfFtj6Q1l8p6QOtOqY8JHVLuknSpWl+B0k3pNjPlzQ1tW+W5u9Iy+dVbOOk\n1L5C0iGtOZL8JM2UdIGk29P53qeTz7Okv0v/ppdLOk/StE48z5LOkvSIpOUVbQ07r5IWSLo1fc/p\nkjSmACOibT9AN3AnsCMwFbgF2LXVcU3geLYD9kzT04E/AbsC/wwsSe1LgC+n6UOBywEBewM3pPZZ\nwF3p69ZpeutWH1+d4/574Fzg0jT/Y+DoNH0G8LE0/XHgjDR9NHB+mt41nfvNgB3Sv4nuVh/XKMf8\nb8BH0vRUYGannmfgRcDdwOYV5/eDnXiegdcBewLLK9oadl6B3wH7pO+5HHjLmOJr9Q9ogj/cfYAr\nKuZPAk5qdVwNPL6LgTcBK4DtUtt2wIo0/R3gPRXrr0jL3wN8p6J9yHqT6QPMAa4C3gBcmv4hrwV6\nqs8xcAWwT5ruSeup+rxXrjcZP8CMlABV1d6R5zkl/PtSAutJ5/mQTj3PwLyqhN+Q85qW3V7RPmS9\nPJ92L+kM/kMatDq1tb30Z+wewA3ACyLiQYD09flptZGOv51+Ll8HTgQG0vw2wOMR0ZfmK2P/y3Gl\n5U+k9dvpeCH7i3QNcHYqZX1X0pZ06HmOiPuBrwL3Ag+SnbdeOv88D2rUeX1Rmq5uz63dE36t+lXb\n9zOVtBXwU+D4iFhXb9UabVGnfVKRdBjwSET0VjbXWDVGWdYWx1uhh+zP/m9HxB7Ak2R/6o+krY87\n1azfQVaGeSGwJfCWGqt22nkezViPc8LH3+4JfzXw4or5OcADLYqlISRNIUv250TEz1Lzw5K2S8u3\nAx5J7SMdf7v8XPYD3i7pHuBHZGWdrwMzJQ2+b7ky9r8cV1r+POBR2ud4B60GVkfEDWn+ArJfAJ16\nng8C7o6INRGxCfgZsC+df54HNeq8rk7T1e25tXvCvxHYKd3tn0p2g+fnLY5p3NId9+8Bt0XEaRWL\nfg4M3qn/AFltf7D9/elu/97AE+lPxiuAgyVtna6uDk5tk0pEnBQRcyJiHtm5+1VEHANcDRyZVqs+\n3sGfw5Fp/UjtR6feHTsAO5Hd3JqUIuIh4D5JO6emNwJ/pEPPM1kpZ29JW6R/44PH29HnuUJDzmta\ntl7S3unn+P6KbeXT6hscDbhBcihZb5Y7gc+2Op4JHsv+ZH+iLQNuTp9DyeqXVwEr09dZaX0B30rH\nfiuwsGJbHwLuSJ9jW31sOY79AJ7rpbMj2X/kO4CfAJul9mlp/o60fMeK7/9s+jmsYIw9F1p0vPOB\npelcX0TWG6NjzzPwBeB2YDnwQ7KeNh13noHzyO5TbCK7Iv9wI88rsDD9DO8EvknVjf/RPh5awcys\nJNq9pGNmZjk54ZuZlYQTvplZSTjhm5mVhBO+mVlJOOFbR5K0IX2dJ2lRg7f9v6vm/6uR2zcrihO+\ndbp5wJgSvqTuUVYZkvAjYt8xxmTWEk741ulOBV4r6eY0Jnu3pK9IujGNQf5RAEkHKHsXwblkD8Eg\n6SJJvWkc98Wp7VRg87S9c1Lb4F8TSttensYsf3fFtq/Rc+PfnzPmcczNGqBn9FXM2toS4ISIOAwg\nJe4nIuLVkjYDrpf0H2nd1wC7RcTdaf5DEfGopM2BGyX9NCKWSPpkRMyvsa8jyJ6g3R3YNn3PdWnZ\nHsAryMY+uZ5sHKHfNP5wzUbmK3wrm4PJxi+5mWzo6W3IxmQB+F1Fsgf4W0m3AL8lG8xqJ+rbHzgv\nIvoj4mHgWuDVFdteHREDZENmzGvI0ZiNga/wrWwEHBcRQwYZk3QA2TDFlfMHkb1g4ylJ15CN8TLa\ntkfyTMV0P/6/Zy3gK3zrdOvJXhc56ArgY2kYaiS9LL18pNrzgMdSsn852SvoBm0a/P4q1wHvTvcJ\nZpO97q4dRnO0kvBVhnW6ZUBfKs18H/gGWTnl9+nG6Rrg8Brf90vgbyQtIxuZ8bcVy84Elkn6fWTD\nOQ+6kOxVfbeQjXp6YkQ8lH5hmLWcR8s0MysJl3TMzErCCd/MrCSc8M3MSsIJ38ysJJzwzcxKwgnf\nzKwknPDNzErifwA+mHrfhQstCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last guess:  [1.52570509e-40 1.00000000e+00 9.44838718e-51 1.00000000e+00\n",
      " 1.00000000e+00 5.13375627e-57 1.22763171e-11 1.00000000e+00\n",
      " 9.99999943e-01 6.02932446e-17]\n",
      "actual vector:  [-1.04928655  1.1363447  -1.30730034  1.01404528  0.79769454 -1.41931688\n",
      " -0.26487139  1.05126584  0.14355861 -0.38944272]\n",
      "difference:  [ 1.04928655 -0.1363447   1.30730034 -0.01404528  0.20230546  1.41931688\n",
      "  0.26487139 -0.05126584  0.85644133  0.38944272]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.9210769525032294"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test with dummy data\n",
    "num_tests = 10000\n",
    "inputData = []\n",
    "targetData = []\n",
    "\n",
    "vec = np.random.randn(10)\n",
    "#Generate data where targets are the same as the input vectors\n",
    "for test in range(num_tests):\n",
    "    inputData.append(vec)\n",
    "    targetData.append(vec)\n",
    "\n",
    "#moment of truth let's gooo\n",
    "trainNetwork(inputData, .001, [10, 10], targetData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INCORRECT: SHOULD TEST DIFFERENCES IN WEIGHTS INSTEAD OF INPUT VECS\n",
    "#new notebook has correct test\n",
    "#sanity check numerical differentiation\n",
    "\n",
    "#calculate f(x + 10**-6)\n",
    "errVec = inputVec + 10**-6\n",
    "activations1 = forwardprop(errVec, weightMatrix)\n",
    "deltas1 = calcDelta(activations1, targets)\n",
    "alldeltas1 = backprop(activations1, weightMatrix, deltas1)\n",
    "updatedW1 = calcGradient(.001, alldeltas1, activations1, weightMatrix)\n",
    "\n",
    "for entry in range(len(updatedW1)):\n",
    "    #for each layer of network, return (f(x + 10**-6) - f(x)) / 10**-6\n",
    "    diff = (updatedW1[entry] - updatedW[entry])/ 10**-6\n",
    "    print(\"diff\")\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
